# -*- coding: utf-8 -*-
"""Chapter 3 decisiontree_iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VkZrkEqRnvRAMZ1cVh9tiNXLTb_k-hg9
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os # use commandline  
import pandas as pd
from google.colab import files
import io
uploaded = files.upload()
iris = pd.read_csv(io.BytesIO(uploaded['iris.csv']))

iris.head() #iris.tail()

import seaborn as sns
sns.set(style="ticks")
sns.set_palette("husl")
sns.pairplot(iris.iloc[:,1:6],hue="class")

#shape of datasets 
print ("Dataset Shape: ", iris.shape) 
iris.describe()

iris.info()

iris.groupby('class').size()

import matplotlib.pyplot as plt
sns.set_style('whitegrid')
g = sns.FacetGrid(iris, hue = 'class', size = 5)
g.map(plt.scatter,'sepallength','petallength')
g.add_legend()
plt.show()

# Reading the Iris.csv file
X = iris.iloc[:,0:4].values
y = iris.iloc[:,4].values # attribute 4 is label data

# Import Library for splitting data
from collections import Counter
from sklearn.model_selection import train_test_split
# Creating Train and Test datasets
X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 50, test_size = 0.25)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
print(Counter(y_train))
print(Counter(y_test))

# Creating Decision Tree Classifier
# see https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html
#DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset.
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

clf = DecisionTreeClassifier()
clf.fit(X_train,y_train)

# Predict Accuracy Score
y_pred = clf.predict(X_test)
print("Train data accuracy:",accuracy_score(y_true = y_train, y_pred=clf.predict(X_train)))
print("Test data accuracy:",accuracy_score(y_true = y_test, y_pred=y_pred))

#show confusion matrix 
from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,y_pred))

#Measures of the predicted values
print(classification_report(y_test,y_pred))

from sklearn import tree
tree.plot_tree(clf)

#use Entropy
clf = DecisionTreeClassifier(criterion='entropy',max_depth=3) #set max_depth = 3
clf.fit(X_train,y_train)

# Predict Accuracy Score
y_pred = clf.predict(X_test)
print("Train data accuracy:",accuracy_score(y_true = y_train, y_pred=clf.predict(X_train)))
print("Test data accuracy:",accuracy_score(y_true = y_test, y_pred=y_pred))

# Generating the decision tree graph
from sklearn import tree
tree.plot_tree(clf)

#Convert decision Tree to Dot file
#export_graphviz function converts decision tree classifier into dot file 
#pydotplus convert this dot file to png or displayable form on Jupyter.
from six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
dot_data = StringIO()
feature_cols = ['sepallength', 'sepalwidth', 'petallength', 'petalwidth']
export_graphviz(clf, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True, feature_names = feature_cols,class_names=['Iris-setosa','Iris-versicolor','Iris-virginica'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('iris.png')
Image(graph.create_png())
#Values are number of instances per class.

#the tree can also be exported in textual format with the function export_text.
from sklearn.tree import export_text
clf = DecisionTreeClassifier(random_state=0)
decision_tree = clf.fit(X_train,y_train)
rules = export_text(decision_tree, feature_names=feature_cols)
print(rules)

# prediction on X_test (testing data ) in order to compare actual target with 38 instancs
Y_pred=clf.predict(X_test)
print(Y_pred)

# prediction on unseen data
X=[[3.2,1.8 ,5.6 ,1.1],[6.4,1.8 ,6.6 ,2.1]]  #two unseen data
Y_pred=clf.predict(X)
print(Y_pred)

"""# Exercise 
ให้นักศึกษาทดลองจำแนกชุดข้อมูล bank-data.csv ด้วย decision tree
โดยให้ดำเนินการดังต่อไปนี้
1.  ดูข้อมูลและรายละเอียดของข้อมูลทั้งหมด
2. ลบattribute ที่ไม่จำเป็นออก
3.  จำแนกข้อมูลโดยให้ได้ค่าประสิทธิภาพสูงที่สุดโดยแสดงค่าทั้ง accuracy precision recall f-measure  และสร้าง model
4.  วาดต้นไม้และกฎที่ได้จากการเรียนรู้
5.  ทดลองสร้าง unseen data ขึ้นมาสัก 3 รายการแล้วนำไปจำแนกข้อมูลด้วย model ที่มีค่าสูงที่สุดที่ได้
"""