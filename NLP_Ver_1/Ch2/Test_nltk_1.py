from nltk.tokenize import word_tokenize
print(word_tokenize("Hi there!"))
#สามารถแยกเป็นคำ ๆ ได้เลย