# -*- coding: utf-8 -*-
"""CNN_classifiy_fashion_mnist (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TOb14xhkkN3dnDsn6qdvpfDfOawxbhEn
"""

import keras
print(keras.backend.backend())
import tensorflow as tf
print(tf.__version__)

#fashion_mnist = keras.datasets.fashion_mnist
from keras.datasets import fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

import matplotlib.pyplot as plt #เป็นการ plot ภาพ
plt.imshow(train_images[0], cmap='gray') #gray scal สีเทา

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images.shape

len(train_labels)

train_labels

test_images.shape

len(test_labels)

# Helper libraries
import numpy as np

plt.figure()
plt.imshow(train_images[9])
plt.colorbar()
plt.grid(True) #ถ้าจะแสดง grid ก็ใส่ true
plt.show()

# normalize to range 0-1
train_images= train_images / 255.0

test_images = test_images / 255.0

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1) #วนทีละ 5 แถว 5 คอลัม
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]]) # แสดง label แต่ละ picture ก็คือ เฉลยของแต่ละภาพ 
plt.show()

import matplotlib.pyplot as plt
n=25
plt.figure(figsize=(10,10))
for i in range(n):
  plt.subplot(5,5,i+1)
  plt.xticks([]) #show label in row and column
  plt.yticks([])
  plt.imshow(train_images[i])
  plt.xlabel(class_names[train_labels[i]])
plt.show()

train_images = train_images.reshape(train_images.shape + (1,))  #ดาต้าเซตชุดเทรดจะต้องถูกนำมา reshape input dene  ใน 1 มิติได้
print(train_images.shape)

test_images = test_images.reshape(test_images.shape + (1,))
print(test_images.shape)

from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D

model = Sequential()
# Add convolution 2D
model.add(Conv2D(64, kernel_size=(3, 3),
                 activation='relu',
                 padding='same', #same’ ที่บังคับให้ชั้นนี้ส่งออกข้อมูลขนาดเท่าเดิม ทำได้โดยการเพิ่มขอบที่มีค่า 0 (zero padding) และ ‘valid’ ที่อนุญาตให้ข้อมูลส่งออกมีขนาดเล็กลง
                 input_shape=(28,28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, 
                 kernel_size=(3, 3), 
                 padding='same',
                 activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten()) #7x7x32
model.add(Dense(256, activation='relu'))
model.add(Dense(10, activation='softmax')) #ต้องดูตามคำเฉลย ว่าจะใช้ activation อะไร
model.summary()

model.compile(optimizer='adam',  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  metrics=['accuracy']) #วัดประสิทธิภาพด้วย metrics=['accuracy'] สูตรคำเฉลยโดยการ SparseCategoricalCrossentrop

#model.fit(train_images, train_labels, epochs=10)
history = model.fit(train_images, train_labels, batch_size=100, epochs=3,validation_data = (test_images,test_labels),callbacks =None)

print(history.history.keys())
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'],loc = 'upper left')
plt.show()

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\nTest accuracy:', test_acc)

probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])

predictions = probability_model.predict(test_images)

predictions[2]

np.argmax(predictions[test_labels[2]]) #อันนี้คือตัวที่เอา model มาทำนายและไดคำตอบมาว่าเป็นประเภทที่เท่าไหร่

test_labels[test_labels[2]] #อันนี้คือเฉลยคำตอบดูว่าตรงกับที่ทำนายไหม test_labels[] คือชื่อตัวแปล array ที่เราสร้างขึ้นมาเองเพื่อเก้บเฉลย